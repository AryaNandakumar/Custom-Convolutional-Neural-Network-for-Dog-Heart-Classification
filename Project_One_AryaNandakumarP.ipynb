{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "009e8fc2",
      "metadata": {
        "id": "009e8fc2"
      },
      "source": [
        "# 1. Build your own convolutional neural network using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "133be475",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "133be475",
        "outputId": "3170116e-2e4e-439d-8968-555af63dd0b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DogHeartCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=32768, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DogHeartCNN(nn.Module):\n",
        "    def __init__(self, num_classes=3):  # Updated for 3 classes\n",
        "        super(DogHeartCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Batch Normalization\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)  # Adjust based on image size\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, num_classes)  # 3 output classes\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # No activation, handled in loss function (CrossEntropyLoss)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Model initialization\n",
        "model = DogHeartCNN(num_classes=3)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c45b84",
      "metadata": {
        "id": "a0c45b84"
      },
      "source": [
        "# 2. Train your model using dog heart dataset (you may need to use  Google Colab (or Kaggle) with GPU to train your code)\n",
        "\n",
        "### (1) use torchvision.datasets.ImageFolder for the training dataset\n",
        "### (2) use custom dataloader for test dataset (return image tensor and file name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "50effdac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50effdac",
        "outputId": "435a96c7-8677-4051-de90-8e60ae3b4237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "g_CT08zO7J-8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_CT08zO7J-8",
        "outputId": "7451e5e4-89b8-4857-f3b8-3aaa2fc13703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Large', 'Normal', 'Small']\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
        "    transforms.ToTensor(),          # Convert images to tensors\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalize (adjust if needed)\n",
        "])\n",
        "\n",
        "# Paths\n",
        "train_dir = \"/content/drive/My Drive/Dog_heart/Dog_heart/Train\"\n",
        "valid_dir = \"/content/drive/My Drive/Dog_heart/Dog_heart/Valid\"\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(root=valid_dir, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Class names\n",
        "class_names = train_dataset.classes\n",
        "print(\"Classes:\", class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "wHBAKcyH7Po3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHBAKcyH7Po3",
        "outputId": "319bcca0-6444-4648-a9b1-2d871d50b2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([32, 3, 128, 128])\n",
            "File names: ('1624.png', '100.png', '1627.png', '1631.png', '1628.png')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# Define a custom dataset for testing\n",
        "class DogHeartTestDataset(Dataset):\n",
        "    def __init__(self, test_dir, transform=None):\n",
        "        self.test_dir = test_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(test_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.test_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name  # Return both image tensor and filename\n",
        "\n",
        "# Test dataset and DataLoader\n",
        "test_dir = \"/content/drive/My Drive/Test/Test\"\n",
        "test_dataset = DogHeartTestDataset(test_dir, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Check test data\n",
        "for img, filename in test_loader:\n",
        "    print(\"Batch shape:\", img.shape)\n",
        "    print(\"File names:\", filename[:5])  # Print first 5 filenames\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "jIjYItVn9iNM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIjYItVn9iNM",
        "outputId": "b2cf391e-7551-410b-b1a6-c3f2b3680080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Move the model to GPU\n",
        "model = DogHeartCNN(num_classes=3).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ya5S_OK94oI",
      "metadata": {
        "id": "4ya5S_OK94oI"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "S5xaINXi-CyC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5xaINXi-CyC",
        "outputId": "529ebf58-3035-4a55-c303-056856a5b0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.3405, Train Acc: 85.36%\n",
            "Validation Accuracy: 70.50%\n",
            "\n",
            "Saved best model with validation accuracy: 70.50%\n",
            "Epoch [2/10], Loss: 0.2772, Train Acc: 89.07%\n",
            "Validation Accuracy: 69.50%\n",
            "\n",
            "Epoch [3/10], Loss: 0.2432, Train Acc: 91.79%\n",
            "Validation Accuracy: 71.00%\n",
            "\n",
            "Saved best model with validation accuracy: 71.00%\n",
            "Epoch [4/10], Loss: 0.1775, Train Acc: 94.36%\n",
            "Validation Accuracy: 67.00%\n",
            "\n",
            "Epoch [5/10], Loss: 0.1375, Train Acc: 96.36%\n",
            "Validation Accuracy: 69.00%\n",
            "\n",
            "Epoch [6/10], Loss: 0.1056, Train Acc: 97.14%\n",
            "Validation Accuracy: 69.50%\n",
            "\n",
            "Epoch [7/10], Loss: 0.0763, Train Acc: 98.79%\n",
            "Validation Accuracy: 71.00%\n",
            "\n",
            "Epoch [8/10], Loss: 0.0794, Train Acc: 98.36%\n",
            "Validation Accuracy: 69.50%\n",
            "\n",
            "Epoch [9/10], Loss: 0.0511, Train Acc: 99.07%\n",
            "Validation Accuracy: 70.00%\n",
            "\n",
            "Epoch [10/10], Loss: 0.0345, Train Acc: 99.64%\n",
            "Validation Accuracy: 69.50%\n",
            "\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10  # Change based on performance\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move to GPU\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {val_acc:.2f}%\\n\")\n",
        "\n",
        "    # Save the model if validation accuracy is the best so far\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"Saved best model with validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "\n",
        "print(\"Training Complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f63262f",
      "metadata": {
        "id": "7f63262f"
      },
      "source": [
        "# 3. Evaluate your model using the developed software"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687038bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687038bb",
        "outputId": "89eebc70-c269-41e4-d553-e1df4dcdc995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved as predictions.csv!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))  # Load the saved weights\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# Store predictions\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, filenames in test_loader:\n",
        "        images = images.to(device)  # Move images to GPU\n",
        "        outputs = model(images)  # Get predictions\n",
        "        _, predicted = torch.max(outputs, 1)  # Get class index (numerical)\n",
        "\n",
        "        # Store filename and numerical label\n",
        "        for filename, label in zip(filenames, predicted.cpu().numpy()):\n",
        "            predictions.append([filename, label])\n",
        "\n",
        "# Convert to a DataFrame and save as CSV\n",
        "df = pd.DataFrame(predictions, columns=[\"image_name\", \"predicted_label\"])\n",
        "df.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved as predictions.csv!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5846bc",
      "metadata": {
        "id": "1b5846bc"
      },
      "source": [
        "# 4. Compare results with [RVT paper](https://www.nature.com/articles/s41598-023-50063-x). Requirement: performance is better than VGG16: 75%"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAArYAAAFMCAYAAAA+4v8OAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACPkSURBVHhe7d1vaFz3ne/xj2Q7bOvu3QFDxn96O7F2N8IuwSHFciOoXAus3geRrVUsm8oRtagUuBtM6KJrgqvUOFZN0B0oxYRCpCAXJQryuFpZ6oNbGWSsglyPcYgJVVFuK3l6Y0fzwDBb6u4SW9J9cP7MmTNnRjOK/8z8/H7BgH3+nzOao8/8ft/fUUUqlVoWAAAAUOYq/RMAAACAckSwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEqUqnUsn8iStP8/LwSiYTu3Lmj+/fv+2cDj9zatWu1YcMGRSIRbd261T8byGlo/ikNJ9bp+p01+uv9Cv9s4JH72tplfWvDog5F7ql16xf+2SgTBNsysLi4qOnpaS0tLWnbtm3atGmTnnrqKf9iwCP3xRdf6PPPP9cf/vAHVVZWqra2VmvWrPEvBrj+a1Fqn/6q/nOpUq9tW9LuTcv6B25nKAH/8YV0+fMKvfOHSn2lckkDtX/T33E7KzsE2zLw29/+VqFQSDU1NVpaWtLyMm8ZSkdFRYUqKysVj8eVSqX0ne98x78I4Pr+b7+qfw5V6H/XLHE/Q8lx7mf/K16p/5ta1off+Zt/EZQ4gm2Jm5+f15///Gd973vf0+Lion82UDLWrFmj3/zmN/rGN75BWQICDc0/pXN/fkr/53v3uZ+hpK1Zs0b/4zdrdfAbX1CWUGYYPFbiEomEtm3bxi8BlLzFxUVt27ZNiUTCPwuQJA0n1ulfty1yP0PJW1xc1L9uW9RwYp1/FkocwbbE3blzR08//bR/MlCSnn76ad25c8c/GZAkXb+zRnVPL/knAyWp7uklXb9DkW25IdiWuPv372vdOr4xojysW7eOJ3Ygp7/er9DfryPYojz8/bolnthRhgi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRZfSjLWqvXr13terTp3y7/U43X1be/xrdf6tnNK+hda6VxunVPr+vVqjQWtKUlJnWvLte2r6s3YbuarN55exvq3fcxvX/VtB0AhCv3M55b5efxyVrOtq7pa1PLBnHta7vsWYB6CLVbJCnJVR57X5N27uuu8Pm3S6LMlciO1w2i9JtPHd/euJr/Zrqr1vfLGxqtvr1fVWJPmvOdy6Xm1P2v/QtpyUK+/KV0Yuxz8C/LWZY2OSCeOHlTYP8924pJn257XsRpJ2qVj7r8BrEoRn/nSdVW96+t12T+5aFf1yyMXtL95vy4c+WWZnDvw5RFssSrJ2I/UrgHN3T2mXd4ZWw5q6NMB6UhVkS0UD1pS595o14U3J3X3jYwj1K435jTQfFL1bovoVV0+FRBKa45p8k3p5KS13K76E9JIu34ZcF7J6VFd0AntJpgCj0kxn/knQPyyTuqEXn+7Sft1UpcD7luAiQi2WAWrJSArCDrs1k0nEFqtKK06F+sN7ua3ZXYfZs53uuYzlsnXvXjrskZH9mugLfMXnCWsg4N3s375fZzI3tquNzzL1fxAA82e83LZLSNnf5AZ8ouyUnelXergXp9yaX0CHpEiP/NZ5QoB9yQvf6mS2yvl3N+86wZN88i9b6u19qSkk3syy5Hy3R+DXJ08Kb25W7u27FZT4H1LUtx7T/aXP/nvOel9JmOtWfffzGlX1Ztxz7fvV3aLeu595rrO1rH4ewIp2UIQgi2Kdyuhj7Vfz2zxz0jbVX9COnXZE74uqP2I3LKFubNS+7NOOLNuWhndh5eeV/uzvpv3qXpdrne6Fyd1YqRdP8pV8nDrpi7oeUXyHGPaLv3g7H5dOFKVeRPOEtbufft95+W0jOxXU21gzH8Arqp3fZVG982512fu7Meqz3mcwBOoiM98Mtaq+t8PeEqP5jTQfEHtbwR/WU7GWlV1RBr41F7+S/RK5d/3Lh27O6kTTunSG7sKvz963Tqnn5+STtTvskL9Uf/92A61e056SqQmdeJUvSdIVtm9ckH37EJcUPvYM/b6x7RLV9X7bLue95ZkXTohnap3r2Pu62zdezNLweyetvqgLzJ4khFssUqF/QLxOnEpXbYQbvmZBppP6uexpN3SckKT3hbUmmOafPOC2gc9t9HmAf3A7erfpd1vShf+dDM936/5GT3jn5ZDuGXIurFLkk6q3mkx8LVKhFte1wnZx22zWkZe18EVrsfJPb6WikIHdcQv62TzgH7Wkg7OGdcPgKXAz3y4ZUh3B709TvaX1kBJXR67oP1nf5b+jG85qKFV1sQXt2+nJbqA+6NHcnpUF7z3y5rdOe5bk55zsOr8h1rC6dbvt9PHad0jfaVnK9i/b7fnPAPGEdTstu+5WvE6h2ubtH9kVJedMG+XWlD+BT+CLVbpYyVytRYE8rfwhhX5ph1Mb93UBW+YtF/1p7zLS/pmJLj0IZeRm8oTewNYN950q+h+aaRdVRldXXagdlsOCm81CBo8NuQJq7kkEx9bx5FxfarUPuJfEnjCFfuZ93TFVx254J9ru6mbI9LzkZU/q0UpaN9OS3QB90eXHRB9oTLzvpVU4vfS/n/M8TWgiNbvfIKvmbfEwSq7sKxwnbfsVlPzBY1O23dep9TCvxyeeARbFG9LRM/rgm7mCbbF3HSSiY8lnch8uoLz8tXBFmzLM9qfL3zHe7NaY/3CLUNWuPV14e1qG3BbDpKxn+tkRkvyg3fzTxekZm/XZXHBGHgiFPGZd+s493zsdnvPnc3TavoAFbvvou+P8V+qfUSe0ipPEPa2eD5yzmMPq9T+TaeswuklK4RVUmGF88IbFPDkIdhiFaya1JNncgTDjPouhz8Ip1sMwpHnV9ECvIItB/V6zq66pM6dOem2AFu/aIJrx6xj83FbDq4GtIw8eM/84/7iW6KAJ03Bn3mny3tOd+8Oud3eN/+Uq9X0GT3THDy4NKdbNxW8tWL37dyDCr8/Xp08meOL8KROyLk+nh6zICt9SQiQ7xykdOnApDeQ30roY3eBAq5zzW6dGBnV5RhlCMiNYItVCbf8TAMKeDbkrXNqfbZdOjuXVX92ck962WTsR2ofOaHXW8L20wb8Azesb/cF1aDmsKttQPtP1WeNmr36dpXaPTVrTt1sfVYLrvXLMPtpB3bLwZF6tY88zEFjFvf4vOdhjy5ezeAVwFSFfualzFCXjLXm6dq3By5lPAvWM0rf7sFKB2o7ROeRf9++gFfU/THHowsltxzB6YGyBvj+PPDpM86X94wvCZ4nPYQjz2c++tBuzFiZNyxbg8nScXiF6yzZ53BB7UcK7xHEk4dgi1WyH59zSZm1X8+OqunToC7y/Ro4m17W+sMOzkCEsA4OztlBOV179fHZuYDtFGHLQQ3dndPA7+szu+R+73/+rlVbaz3E3VvHVqWbR4POxTPooYBBY1+ePVL6lOc87NHF/i8PwBOtoM98WAcHMz9PVWNNmrt0ImdXvVWW9LHnXmc9pcS6N+zSsU/tQL1+vdav/5F0dEDBxQWF7NsJeFV26UTh98dk7Od5WzJ3tQ2kn2lbc8z9IzTudZLzDGB7n97r+Oyomj61W5lrjmnu7P70gNg3pNfzlFNIzjry7K9eujSX8QjF/NfZsqveKl6gDAG5VKRSqWX/RJSO4eFhvfLKK/7J5eXWObV6b4ow2vvvv69Dhw75JwMKDf+D7r7yN/9koHDxXq3fI0/DyMO1/v2vKnXoP/yTUcJosQUAAGXh6mRQeRiQRrAFAAClzR5XUP/7zGd6A34EWzx8Ww5qyDMCGACAoth/rCHzj1sA2Qi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItiVu7dq1unfvnn8yUJLu3buntWvX+icDkqSvrV3WX+5V+CcDJekv9yr0tbXL/skocQTbErdhwwYtLCz4JwMlaWFhQRs2bPBPBiRJ39qwqKkFfu2gPEwtVOpbGxb9k1HiuMOUuEgkotnZWf9koCTNzs4qEon4JwOSpEORe/rFLC36KA+/mF2rQxF6TMsNwbbEbd26VZWVlbp+/bp/FlBSrl+/rsrKSm3dutU/C5AktW79Ql+pXNIb19f5ZwEl5Y3r6/SVyiW1bv3CPwslriKVSlFAUuIWFxc1PT2tpaUlVVdXa+PGjVq3jl8MePzu3bunhYUFzc7OqrKyUrW1tVqzZo1/McD1X4tS+/RX9Z9Llfqf1fdVt3FJ/20dv4bw+P3lXoWmFir1i9m1+krlkgZq/6a/43ZWdgi2ZWR+fl6JREJ37tzR/fv3/bOBR27t2rXasGGDIpEILbUoytD8UxpOrNP1O2v01/sMKMPj97W1y/rWhkUdityjpbaMEWwBAABgBGpsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItih/t2NqC4UU8rzazif9S5ntdkxtoTbFblv/jfeGFOqN+5fKIan4tfT1Km5dlCTPZ6KQz4L3PU+eb1PoSEwrrwUApYdgi7KWPN+m0PZO7biYUirlvGa179fVT/Qv55pjKaWO1fgnB0gqdqRaZxLpKYWvi1IVf79T48cnlEqlNHgg7J8NAMYi2KJ83Y6pq0Pqm0mpa6d3RlgtZ2fVp05V0/KIJ05SiRmpsSrinwEAxiPYomxZrVJH1bLZP0dWuH2tWzo9JSvaxhUNhRQ9n1m2EL3mW+1aNGdJg9NFGz/f5lkmam8/yMr7TJ5vU6g3ptgR3/785RX+gO6bH53OnJ1VTuA7L2ue1VrbOSqNd6RbuLPWzXcsTgnEtdzn6FyHwq6ZVlg+17ykYkcCut2vRfPsz1onva10KYf73gWcR9b75zmezP3nOlZbnp81rXrbcUVDnvc0FFXcV6YiZZeuBAu+plk/HwBQQgi2KFMFtErtrFO3ejTlCSI9HWPaN2OXLFzsVs/e9C/35Pk2hfZKE25Jw4R2dFRn/mIf7dQZRd2Sh76mHjWs8Es+3z4lSac7lXjNmj94IGwFnu2edVKz6ptp8ISJuKLbO6X+Wfc41dGpcc8mM1yLKrS3R91uucaEuk83qO28rJbtJqmxf1apsy3K6rS+FvWVeljrZgabcXW+I0Xt6zbb36ievd7A2aAb7rGmNHE83zWLKxpqUI/dje4ufySmZN5thVX3UqPGOwYzwmP8Uo90vE5BhRXx3mp1bk/vZ7Zf6jxeePlK8nybqu0eg1QqpdRMn9RRbQfffOdRwM/ataiqO3ak58/0SR1d9s9NvutQo66U5z1NdQWee2Hsa/rrKc81iWvqtNS9Z/VbBYCHiWCLsrYjkhXF8mrsj6ZbeHd2aeL4uDrfj0tKaurX4+q+6A0CNeq62O0LS9066tYsWr/4NZPIG4Zy79PRrTpPKUX8Uk/mOgqr5XSfGk+fUey2lDx/Rj1NfYq6x2EdZy5WuJvwlGvUqKvA2svAdS96W8It3a+lQ3G4dp8adUOJ25KUUGLUs+BKNbzXptSjbk145tccS9mhO/+2wgeO+r7I5Ath1hcjr/CBweBwH8j6ecl4nza3aDBll8XkPY+Vf9aSiRvuHMnZ9qC9r/zX4UEK1+5T4+iYppwvYvZ5eX9eAaCUEGxR1m4k8kXKbP4gHKlygqkVFnr2ert3Qwrt7clYXk0R5WkjDpR7n7aMbVqBy+pG9hzH9nSLbGJuXNoeyQxgWyJq9P7fVUDLdk451t1Zp243uEpSoyJbMhdJq1Fbf6PnfHKVBViSiRt5rvFK26pR3XGp55I9NW8Ic0pVGuxtrdQt72f9vPjfW0f+81j5Z80J6Q2BZQgrXYcHaHOd9jWNa2za2n++FnAAKAUEW5SpsCLbpfE5z3B+v7zBxud2QjckT3e99/VlunOLZYUeqxvZfxxOi91jZl+rQoUPDLrd7emwtrowttK2avakW5Otlu+23O/dzi57W7PqaxpX5/bVBNxVKOhnzWpVT9mlHU6IdQLuStfhwbG+AFjlCPlawAGgNBBsUbZqXkl3z2dLKvZOduuSv4XXbf3cHNGOgPkPgn+bgS2urogiTfkDe1aLryTdSuSosS3gC0BOOda9ldC4dihSdMh2wpoVxry1z45wZIc0mtDKR5tjW05d9fmYzpxu1L7a4KucKayWs+mA67ROZskI9Nb75H9vHXnPo8ifNSfEzvb7612V+zqsJOfPS4CddeoeHdPU+SK+KALAY0KwRfna3KJov9S53T963R7trz7N+uoOx90BONYAnYbTjep7pcbTveuZ74wA/5LPw829zyDpLvLs0fdWi1z4wFF1j3aqy+2ejivqL5nwsFoxM78ApEe25wivNmtd77HY+yq4O9oavZ/RlZ6vJd0OpmcylneebFDItqz3saejU+NN+1SXM3zbT0TIeMLDlMZGnTBsBdeed9Lvffx97wC9oMFqnqcI5D2PlX/WvO+3xa7pfalO4YKug8fmiHbIW9dtf+krWI3qjo+rs6OY9x0AHg+CLcqa1Zo1IWXUK1Zr7KXgUf7d/fs0tt2pabyhvpl09374wKA1Mt6ZHwqpYaZPswHbKUa+fQba2WU/PSF9HNYIeW83tTWK3prfIPX35aixdba3I/O8NOEONnLCa2BX9s4upWb6dMM9Fnukf8EDlWrUZT8twH1/9t5Q34xzLv5HSvnPLWQ/PaBLNStuy2INXpMdAnMJq+Ws/YQHZ1vbO7XjovPe2PNHO1Vtz5/aMyHvED3r5+WGWwfr/NxZg/LyncfKP2vhA4PWkw482+7cPpHedgHXIc1avtE91y7ptTw/LwFq9lhnThkCgFJXkUqllv0TAfNYj1/SRf8fc3iYHsc+gYfgWjQjmANAqaLFFgCQ14oD8QCgRBBsAQDB7L861zDjfW4yAJQuShEAAABgBFpsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjVKRSqWX/RAAoJ8PDw/5JAPBIHTp0yD8JjwHBFkDZGx4e1ne/+13/ZAB46DZt2qQPP/yQYFsiCLYAyt7w8LDa2tr8kwHgoXvqqaf03nvvEWxLBMEWQNkbHh7Wq6++6p8MAI/Eu+++S7AtEQweAwAAgBEItgAAADACwRYAAABGINgCAADACARbAMZa+PBlVVRUBL5e/nDBXe7KKe+8n+pKxlay+bfr3ZYk6bMhvZy1z5c19JmzwBX91Jl+cEiZay9o6GCFfvq7jIkAgAIQbAEYa+P3f6Xl5eWM1+dDzZJ61PX9jZIdUmt/0qNpe/70W92qzQqbaQsfvqxNrS+4yy8vT+uF1k2Z4fazeY0ovU3r9Su1ft2afeVUrbrfmrb299xhbTrlidK/e0+Hn5vWj7+dngQAKAzBFsCT47MhvdY6op4rP9aLkqQrei/j/9KLb06rJ3ZY7wW2mC5o8t9H1Dz0Q3d56UX9cKhZI/8+6YbhhfmPpJat2uou47Wg+U+knr3WFrb+U7P0yby97hX99EVp+s301gEAhSPYlqprUYVCoTyvNsVuS8nzbQodiSnpX/9LSJ5vC9if9Wo7/yD3ZMk8h7iioZCi1/xL5RJX3F222HVRrHhvSKHeuH9ymVjQ0L8d1shbntbQz+b1kZq11W5Jtbyo+rekj+aD2mw3qvXcsn5lt/bmMv/HEem5rcq/VLaFD6P6KCM0AwCKQbAtVTu7lEql7Nes+pqkxv5Zz7RBtWz2r/QANfVp1t2X/ZrpkzqqH3JwrFFXKqWunf7pQeKKhho05f6/mHWxGjXHUkodq/FPLg+/e0+HY836oN0TGz+b14he8AVby8gf5/2TcrBacdNB1mqRbf4kmqO+dqO2Pid1X7TKD+b/OKLmf6nXRl3Re60vuCUSAIDiEWxRuM0tOnpc6rlUri12eJJdudgtvdXl1rk+KFdObdLhWI+nfGBe8zFp5LmudH3tlRd0+L+nw+2Lb06r5ye1qqioUO0nH+id72/0tNbmG1gGAMiHYGuIqV5PyUBWaUJSsSPekoKoHkQ0jfeG1HY+pqi9Xbcl11dG4S9fyCx1iHpaXBVYTuAvjbC2Z7XW9kjq2et0j2evm+9YnBKIuO948l8b/7UMWMdfRpLRde9f3yopUVZJRsC02zG1haKKOcfrTPfvb8Vr7sy3jsW/bL5yA/+84O3arkWzr81jc0WTP0nXtT4oV05VqPYnzfrg/6VrdKUX9ePlZS1762S//UN90DKiwwPOIDF7meVlLZ9r1cbPhvSa3VqbHlj2uT7QYb3mf+ICACAngq0JRjs1VuWUKcyqT52qdsNHXNFQtcZeSpcxzPbfUMNqAse1qBpOS9170l3R4x1jisxY2+3aaQedvdKEW8IwoR0d1enAcy2q6g6pz14ndVHq7BhP78Mneb4tc3m3HKJGXakJdUvqvhjcPW4dy42sdTPC12inzijqKfnoUUOOUCdJ8d5qdW6f8JRoTKhbnnWuRRXa22MdkzP/dIMnSFarU+kyj9l+qXN7Me9FjzrnjlrbPtui8O2Y2rznmEpptr9R4x1dGYE5+BqGVfdSo8Z/PeUJ03FN+d7jnK5FVd2xI/1ez/RJnv1a5TRdKmBLD9/vJtWtHtX7nzTw9a1q1kead8sE0pr/KXjolyMdatNPO8jNKj/I5crAYb1w5cd6MWNg2UbV/0tzESURAACCrRG6dfRA2P63FVY0k7Bb86bU09SnqDtfCh+Iqq+pR2fyDQQb7VS1rxXQCWwZNaxN+1Tn1vomNfXrcXVf9IaZGnVd7NZ4x6DiSir2To8a+6Pp+uCdXZo47i7sY20vY/nNLRosqI42eN1ovz/I5bl2AbJrTGtU5zn++KUe6fiE5/isut/BA2Hp9pTGRhvVd7pF7h4PDBYd/jJC5+YWDfrqrcO1+9To/i/4OjjXMFy7T42jY5pywui1KfWoW3UrXl8pmbiROSHgWEpFzqcUfH2rXtCIL9harbsvbM1d62qF2h5Nex7h5fpsSC9n1NQqXXcbFJY/G1L0kw/0Q3/oBgAUjWBrgqaIIv5ptmTiRkBIrVbnqH9Jn6DBY0GBcnvEDWlSQolRuzTAF4i983dE0mtIUqQqHcMyBS9fmOB1rSCXUMKZkOfa5ePtgm847U5VYkZqrMqxxVsJjWuHIl8q+DUqssU/TW4ZRigUUmh7p9Jt4MHXwbW5TvuaxjU2bUV5K5jXFRS0wweOWq3VQWUIJSb3UwqsR3V1v5j+owxXTtWquyV30Ew/99ZbfuDx9Xq9nFF2IC18+JoOx9LPzvW6MnBYL/xbq31s3oFl9qPFgsIwACAQwdZwibnxnCF10NOK+0DcTuiGUxqQtb/iWiUfmlsJT+grXtyuZfZ2weducX4EbsfUFgopFGrQDeepGTN9nhbblYTV8lq33YpdRBmC5LZGp9zyh+oSDbh5WkvtP+Iw/Va3au0BW7U/6dH0OSdo+ltgrefeSunls/9i2Ua1nvtcH3xiDQ6rqKiw/6BDQBD+3U9V62utTQ8s26TDsgaWAQAKQ7A1XKSqUfK2UD5MmyPaIelGIlewiSjSlD0/MZcragYvX5jgdZOJG6tupXXrTy96g7rVSmsJK7JdGp/LcbW3RNSoG0o43f4FyH1tLMnpMY3bX1zcLyoZ4T34OmTYWafu0TFNnS+8DMHPKqmwA25GqUcpWPnZsy++6f0LYb4A+vVW/cotOfAM+sp6edez9hk8z+PbP7YGj2VM9A0sy5gHAMiHYGs4t7vYOyDKbuV78M+jrVGbb+CSnFbOIzElndZB73x7QFowe3BTx6BncJV3JH++0Oas69nX7Zi6OsbV+FKdp3yieN79xXszyzpq9nRLp89kn39v3O3273zf/15YT0YIR3ZIo50adN6X2zGdyXltPLxfXG7H1OaWfqiAayi7TnhcnR2FlyHILcfwDnyz63m/5PUFAGC1CLbGs58ecLohXfO6vVM7/IPAHpDwgUF7pH+6xrZhpk+zZ+0BUzu7lLq4Iz1/r9TXn7vj3NreDbeOM2Q/4cFqnXRCW3XWY7KcdTP2tb1T6nfWXY0addlPFHDPTROa7W+UTk9ZAc9/fvYy1oCzsFrOzqpvxvtejGnfjD3gameXZvsb0zXKx6Wjea6N7HOcOJ6uc7W2N6Fupetm819DS82ebsk/MG0FWfsOWU+McLdbUo/7AgA8CSpSqdSyfyKAJ8y1qP2YthKphS7S8PCwXn31Vf9kAHgk3n33XR06dMg/GY8BLbYAFL/Uo8b+trIMtQAAOAi2wJPMrrdumMl81jEAAOWIYAs8yew/1pByaqABAChjBFsAAAAYgWALAAAAIxBsAQAAYAQe9wWg7A0PD/snAcAjxeO+SgPBFgAAAEagFAEAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAIBFsAAAAYgWALAAAAIxBsAQAAYASCLQAAAIxAsAUAAIARCLYAAAAwAsEWAAAARiDYAgAAwAgEWwAAABiBYAsAAAAjEGwBAABgBIItAAAAjECwBQAAgBEItgAAADACwRYAAABGINgCAADACARbAAAAGIFgCwAAACMQbAEAAGAEgi0AAACMQLAFAACAEQi2AAAAMALBFgAAAEYg2AIAAMAI/x80fm0eFbLvCwAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "QNYsCkNXesa8"
      },
      "id": "QNYsCkNXesa8"
    },
    {
      "cell_type": "markdown",
      "id": "62f12835",
      "metadata": {
        "id": "62f12835"
      },
      "source": [
        "# 5. Write a four-page paper report using the shared LaTex template. Upload your paper to ResearchGate or Arxiv, and put your paper link and GitHub weight link here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.researchgate.net/publication/390177749_Custom_Convolutional_Neural_Network_for_Dog_Heart_Classification\n",
        "https://github.com/AryaNandakumar/Custom-Convolutional-Neural-Network-for-Dog-Heart-Classification"
      ],
      "metadata": {
        "id": "qU9hxX4-jqYF"
      },
      "id": "qU9hxX4-jqYF"
    },
    {
      "cell_type": "markdown",
      "id": "f476372c",
      "metadata": {
        "id": "f476372c"
      },
      "source": [
        "# 6. Grading rubric\n",
        "\n",
        "(1). Code ------- 20 points (you also need to upload your final model as a pt file)\n",
        "\n",
        "(2). Grammer ---- 20 points\n",
        "\n",
        "(3). Introduction & related work --- 10 points\n",
        "\n",
        "\n",
        "(4). Method  ---- 20 points\n",
        "\n",
        "(5). Results ---- 20 points\n",
        "\n",
        "     > = 75 % -->10 points\n",
        "     < 55 % -->0 points\n",
        "     >= 55 % & < 75% --> 0.5 point/percent\n",
        "     \n",
        "\n",
        "(6). Discussion - 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445593c4",
      "metadata": {
        "id": "445593c4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}